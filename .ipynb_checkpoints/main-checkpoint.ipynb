{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import treebank\n",
    "from nltk.grammar import CFG, Nonterminal, Production\n",
    "\n",
    "%run BottomUpParsing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bikinStandarTreeBank(dataset):\n",
    "    rules = []\n",
    "    abandoned_treebank = []\n",
    "    for tree in dataset:\n",
    "        try:\n",
    "            rules.append(Tree.fromstring(tree))\n",
    "        except:\n",
    "            abandoned_treebank.append(tree)\n",
    "            \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case folding lower case\n",
    "\n",
    "def traverse(tree):\n",
    "    for index, subtree in enumerate(tree):\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            traverse(subtree)\n",
    "        elif type(subtree) == str:\n",
    "            tree[index] = subtree.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bikinProductionRules(rules):\n",
    "    distinct_rules = set(())\n",
    "    for rule in rules:\n",
    "        for prod in rule.productions():\n",
    "            distinct_rules.add(str(prod))\n",
    "\n",
    "    starting_point = []\n",
    "    general_point = []\n",
    "    for rule in distinct_rules:\n",
    "        prod = rule.split(' ')\n",
    "        if prod[0] == 'S':\n",
    "            starting_point.append(rule)\n",
    "        else:\n",
    "            general_point.append(rule)\n",
    "\n",
    "    productions = starting_point + general_point\n",
    "\n",
    "    cfg_rules = '\\n'.join(productions)\n",
    "\n",
    "    grammars = nltk.CFG.fromstring(cfg_rules)\n",
    "    \n",
    "    return grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simbolSimbolNyah(cek):\n",
    "    abjadSimbol = list()\n",
    "    totalSimbol = list()\n",
    "    listSimbol= list()\n",
    "    listPisahKalimat = list()\n",
    "    for c in cek:\n",
    "        if c == \"(\" or c== \")\":\n",
    "            if len(abjadSimbol) != 0:\n",
    "                simbol = \"\".join(abjadSimbol)\n",
    "                if simbol != \" \":\n",
    "                    listSimbol.append(simbol.strip())\n",
    "                else:\n",
    "#                     print(\"listSimbol\")\n",
    "                    listPisahKalimat.append(listSimbol)\n",
    "                    listSimbol= list()\n",
    "#                     print(simbol)\n",
    "                try:\n",
    "                    x = re.search(\"(^([A-Z]*[\\-[A-Z]*]?[\\-[1-9]*]?)$)\", simbol.strip())\n",
    "                    if str(x.group(0)) != \"\":\n",
    "                        totalSimbol.append(x.group(0))\n",
    "                         #   print(x.group(0))\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                abjadSimbol = list()\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "             abjadSimbol.append(c)\n",
    "    else:\n",
    "        if len(listSimbol) > 0:\n",
    "            listSimbol.append(simbol)\n",
    "#             print(listSimbol)\n",
    "            listPisahKalimat.append(listSimbol)\n",
    "            listSimbol= list()\n",
    "            return [listPisahKalimat, totalSimbol]\n",
    "#             print(totalSimbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = open('./db/dataset (cleaning).bracket', 'r', encoding = \"utf8\").readlines()\n",
    "\n",
    "#rules\n",
    "rules = bikinStandarTreeBank(dataset)\n",
    "\n",
    "#ke lowercase in\n",
    "traverse(rules)\n",
    "\n",
    "#production rules\n",
    "grammars = bikinProductionRules(rules)\n",
    "\n",
    "# convert sentences to parse tree (parsing)\n",
    "parser = BottomUpParsing(grammars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = open(\"./db/testset_outputsystem(10).txt\", \"r\", encoding = \"utf8\").readlines()\n",
    "goldstandar = open(\"./db/testset_goldstandard(10).txt\", \"r\", encoding = \"utf8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall  F1 Score\n",
       "0   0.714286  1.000000  0.833333\n",
       "1   0.777778  1.272727  0.965517\n",
       "2   0.875000  1.166667  1.000000\n",
       "3   0.692308  1.285714  0.900000\n",
       "4   0.625000  1.250000  0.833333\n",
       "5   0.571429  0.666667  0.615385\n",
       "6   0.437500  0.777778  0.560000\n",
       "7   0.900000  1.285714  1.058824\n",
       "8   0.428571  1.000000  0.600000\n",
       "9   0.333333  0.600000  0.428571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buatTabel = {\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}\n",
    "for bandel in zip(tes, goldstandar):\n",
    "    simbolCekTes = simbolSimbolNyah(bandel[0])\n",
    "    perKalimatTes = simbolCekTes[0]\n",
    "    totalTes = simbolCekTes[1]\n",
    "\n",
    "    simbolCekGold = simbolSimbolNyah(bandel[1])\n",
    "    perKalimatGold = simbolCekGold[0]\n",
    "    totalGold = simbolCekGold[1]\n",
    "    \n",
    "    ketemu = 0\n",
    "    for index, items in enumerate(perKalimatTes):\n",
    "        for item in items:\n",
    "            cocokin = re.search(\"(^([A-Z]*[\\-[A-Z]*]?[\\-[1-9]*]?)$)\", item.strip())\n",
    "            try:\n",
    "                if str(cocokin.group(0)) in perKalimatGold[index]:\n",
    "                    ketemu += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    presisi = ketemu/len(totalTes)\n",
    "    rikol = ketemu/len(totalGold)\n",
    "    f1 = (presisi * rikol) / ((presisi + rikol)/2)\n",
    "    \n",
    "    buatTabel[\"Precision\"].append(presisi)\n",
    "    buatTabel[\"Recall\"].append(rikol)\n",
    "    buatTabel[\"F1 Score\"].append(f1)\n",
    "else:\n",
    "    tabelHasil = pd.DataFrame(buatTabel)\n",
    "    \n",
    "tabelHasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kera untuk\n",
      "(S (NP-SBJ (NN kera)) (PP (IN untuk)))\n",
      "\n",
      "Grammars: \n",
      "S -> NP-SBJ PP\n",
      "NP-SBJ -> NN\n",
      "NN -> 'kera'\n",
      "PP -> IN\n",
      "IN -> 'untuk'\n"
     ]
    }
   ],
   "source": [
    "sentence = input()\n",
    "\n",
    "try:\n",
    "    parsed = list(parser.parse(sentence.split(' ')))\n",
    "except ValueError:\n",
    "    print(\"Error! Kata dalam sebuah kalimat tidak ada dalam dataset.\")\n",
    "else:\n",
    "    print(parsed[0])\n",
    "    print(\"\\nGrammars: \")\n",
    "    for x in parsed[0].productions():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP-SBJ (NN kera)) (PP (IN untuk)))\n"
     ]
    }
   ],
   "source": [
    "print(str(parsed[0]).replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exampleOutput = open('/Skripsi/db/outputUserExample.txt', 'r', encoding = \"utf8\").readlines()\n",
    "\n",
    "# treelurus = list()\n",
    "# for output in exampleOutput:\n",
    "#     treelurus.append(output.strip())\n",
    "# else:\n",
    "#     treelurusjadi = \" \".join(treelurus)\n",
    "#     print(treelurusjadi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting production rules\n",
    "\n",
    "# distinct_rules = set(())\n",
    "# for rule in rules:\n",
    "#     for prod in parsed[0].productions():\n",
    "#         distinct_rules.add(str(prod))\n",
    "        \n",
    "# starting_point = []\n",
    "# general_point = []\n",
    "# for rule in distinct_rules:\n",
    "#     prod = rule.split(' ')\n",
    "#     if prod[0] == 'S':\n",
    "#         starting_point.append(rule)\n",
    "#     else:\n",
    "#         general_point.append(rule)\n",
    "    \n",
    "# productions = starting_point + general_point\n",
    "\n",
    "# cfg_rules = '\\n'.join(productions)\n",
    "\n",
    "# grammars = nltk.CFG.fromstring(cfg_rules)\n",
    "\n",
    "# print(grammars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputUser = open('/Skripsi/db/outputUser.csv', 'r', encoding = \"utf8\").readlines()\n",
    "\n",
    "# print(outputUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed = list(parser.parse(sentence.split(' ')))\n",
    "# for t in parser.parse(sentence):\n",
    "#     print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
